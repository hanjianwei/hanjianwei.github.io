[
  {
    "objectID": "posts/2015/02/16/backup-mac-appstore-apps/index.html",
    "href": "posts/2015/02/16/backup-mac-appstore-apps/index.html",
    "title": "备份Mac AppStore中安装的应用",
    "section": "",
    "text": "在Mac中安装软件并不像Linux那么方便，它没有一个统一的软件管理器来处理大部分的情况。我同时用了Homebrew、Homebrew Cask和Mac AppStore来安装不同的软件。前者主要用于安装命令行程序，而后两者用于安装GUI程序。有些软件在Cask和AppStore中都有，以前我都是倾向于使用Cask，主要是便于备份，重新安装时比较方便。但是，Cask也有它自己的缺点，比如软件升级做得不好。最近试着去备份AppStore中的程序，希望能够自动化AppStore中程序的安装。\n备份程序主要用了系统的mdfind和mdls命令:\nmdfind \"kMDItemAppStoreHasReceipt=1\" | while read -r app; do\n  echo \"$app\\n$(mdls -name kMDItemAppStoreAdamID -raw $app)\"\ndone &gt; Applications.txt\nApp的程序名及其ID会被写入到Applications.txt中。\n恢复安装时，读入Applications.txt，逐个读入应用，并打开AppStore进行安装：\nwhile read -r app; do\n  read -r appid\n\n  if [[ ! -e \"$app\" ]]; then\n    open -W \"macappstore://itunes.apple.com/cn/app/id$appid\"\n  fi\ndone &lt; \"./Applications.txt\"\n也算一种半人肉的安装方式吧。"
  },
  {
    "objectID": "posts/2015/07/08/smartos-nas/index.html",
    "href": "posts/2015/07/08/smartos-nas/index.html",
    "title": "SmartOS折腾笔记",
    "section": "",
    "text": "前段时间入手了一台Gen8，准备用做家里文件、媒体服务器。看了EXSi、FreeNAS、NAS4Free、Proxmox等方案后，觉得还是SmartOS最好。它支持ZFS，能够更好管理数据、保证数据有效性；此外，它支持kvm虚拟化技术，能够虚拟常见的操作系统，满足各种软件需求；它还支持类似Docker的Zones容器技术，比kvm更为高效。\n\n安装配置\nSmartOS可以装在一个U盘里面。这样的好处很多，比如增加了系统的安全性和稳定性，可用磁盘空间也大了，系统升级也很简单——更新一下U盘就行了。我用了一个16G的U盘，按照官方的教程下载镜像、创建可启动U盘，然后从U盘启动就可以了。\nSmartOS使用了zones技术，U盘启动后进入一个全局的zone(Global Zone)，负责管理其它的zone。一个zone就是一个虚拟化的实例，SmartOS创建的每个虚拟机都是跑在一个单独的zone里面。\nSmartOS使用了ZFS文件系统，所有虚拟机的zone都是存放在一个叫zones的zpool中。第一次启动时，除了让你配置网络，还会要求你创建zones。我有4块3T的硬盘，1块256G的SSD，在启动时选择4块硬盘组成一个raidz来作为zones池。在我的机器上，4块硬盘分别是c1t0d0, c1t1d0, c1t2d0和c1t3d0。\n为了取得更好的性能，用format将SSD（c1t4d0）分为32G和224G两个分区，分别作为ZIL(log)和L2ARC(cache):\n# zpool add zones log c1t4d0s0\n# zpool add zones cache c1t4d0s1\n配置完之后磁盘的信息如下：\n# zpool status\n  pool: zones\n state: ONLINE\n  scan: none requested\nconfig:\n\n        NAME        STATE     READ WRITE CKSUM\n        zones       ONLINE       0     0     0\n          raidz1-0  ONLINE       0     0     0\n            c1t0d0  ONLINE       0     0     0\n            c1t1d0  ONLINE       0     0     0\n            c1t2d0  ONLINE       0     0     0\n            c1t3d0  ONLINE       0     0     0\n        logs\n          c1t4d0s0  ONLINE       0     0     0\n        cache\n          c1t4d0s1  ONLINE       0     0     0\n\nerrors: No known data errors\n如果上述步骤搞错了，可以参照官方的步骤重装。很不幸的是，我安装官方的步骤选择Grub第2项（noinstall）几乎每次都会死机，如果你遇到和我一样的情况，也可以在启动时出现Grub界面的时候，在第1项按e，然后在最后加上destroy_zpools=true的选项，这样启动后就会删除所有的zpool，然后就可以重新配置了。（注意：磁盘上已经有数据的慎用！）\n\n\n创建虚拟机\nU盘启动的SmartOS是一个只读系统，你所能做的事情非常有限。不过SmartOS就是为虚拟化而生的，它支持zones和kvm两种虚拟化技术，前者类似容器技术，具有很好的性能，但支持的OS较少；后者性能不如前者，但能支持大部分常见的OS。\nimgadm和vmadm是管理虚拟机的两个常用命令，前者主要用来管理镜像，而后者用来管理虚拟机。你可以通过imgadm avail来查看已有的虚拟机镜像，用vmadm create来根据镜像创建虚拟机。\n此外，我希望数据能够单独存储，即使虚拟机坏掉或者删除数据仍然存在，因此专门建立一个数据存储的dataset：\n# zfs create zones/datastore\n\nkvm虚拟机\nkvm是从linux移植过来的技术，能支持大部分常见的操作系统，在创建kvm虚拟机之前首先要创建或下载相应的镜像。Joyent已经提供了很多常见的镜像，如果我想装一个debian 8，可以首先进行搜索：\n# imgadm avail | grep debian-8\nca291f66-048c-11e5-98b3-c3f2a972a4cc  debian-8                20150527    linux    2015-05-27T16:24:03Z\n2f56d126-20d0-11e5-9e5b-5f3ef6688aba  debian-8                20150702    linux    2015-07-02T15:37:02Z\n然后可以选择需要的镜像进行下载：\n# imgadm import 2f56d126-20d0-11e5-9e5b-5f3ef6688aba\n创建虚拟机时，首先需要创建一个JSON格式的虚拟机描述文件，下面是debian 8的描述文件，主要是网络设置以及镜像设置：\n{\n  \"brand\": \"kvm\",\n  \"alias\": \"debian\",\n  \"hostname\": \"debian\",\n  \"resolvers\": [\n    \"192.168.1.1\",\n    \"114.114.114.114\",\n    \"8.8.8.8\",\n    \"8.8.4.4\"\n  ],\n  \"ram\": \"2048\",\n  \"vcpus\": \"1\",\n  \"nics\": [\n    {\n      \"nic_tag\": \"admin\",\n      \"ip\": \"192.168.1.102\",\n      \"netmask\": \"255.255.255.0\",\n      \"gateway\": \"192.168.1.1\",\n      \"model\": \"virtio\",\n      \"primary\": true\n    }\n  ],\n  \"disks\": [\n    {\n      \"image_uuid\": \"2f56d126-20d0-11e5-9e5b-5f3ef6688aba\",\n      \"boot\": true,\n      \"model\": \"virtio\"\n    }\n  ]\n}\n具体的可用选项可以查看vmadm的文档以及SmartOS的wiki。\n将文件存为debian8.json，然后就可以通过vmadm创建镜像：\n# vmadm create -f debian8.json \nSuccessfully created VM b94d3a92-4a3b-4fae-baca-e53c726be924\n可以通过vmadm list来查看当前虚拟机的状态。创建好的虚拟机可以通过VNC登录，首先要查看虚拟机的VNC信息，然后通过ip和端口进行登录：\n# vmadm info b94d3a92-4a3b-4fae-baca-e53c726be924 vnc\n{\n  \"vnc\": {\n    \"host\": \"192.168.1.100\",\n    \"port\": 57869,\n    \"display\": 51969\n  }\n}\n我们希望在虚拟机中访问datastore，并将重要的数据存在其中，这样即使虚拟机挂掉也不影响数据的访问。可以通过NFS来进行文件恭喜。首先将datastore共享：\n# zfs set sharenfs='rw=@192.168.1.0/24,root=192.168.1.102' zones/datastore\n在debian里面安装nfs相关的包并将datastore挂载过去：\n# apt-get update && apt-get install nfs-common\n# mkdir -p /mnt/datastore && mount -o rw,async,hard,intr 192.168.1.100:/zones/datastore /mnt/datastore\n在debian虚拟机中就可以将常用数据放在/mnt/datastore中了。\n\n\nzone\nZone是一种更高效的虚拟化技术，但是它适用的OS也比较有限。比如你如果想玩玩SmartOS，那用Global Zone的系统可能不是一个很好的选择，因为它是只读的，而且缺少包管理等工具。我们可以用zone虚拟一个SmartOS，你可以用imgadm搜索并下载base64镜像，并通过下面的JSON文件来创建虚拟机：\n{\n  \"brand\": \"joyent\",\n  \"image_uuid\": \"62f148f8-6e84-11e4-82c5-efca60348b9f\",\n  \"alias\": \"smartos\",\n  \"hostname\": \"smartos\",\n  \"max_physical_memory\": 2048,\n  \"quota\": 20,\n  \"resolvers\": [\"192.168.1.1\", \"114.114.114.114\", \"8.8.8.8\", \"8.8.4.4\"],\n  \"nics\": [\n    {\n      \"nic_tag\": \"admin\",\n      \"ip\": \"192.168.1.101\",\n      \"netmask\": \"255.255.255.0\",\n      \"gateway\": \"192.168.1.1\"\n    }\n  ]\n}\n然后，用vmadm来创建虚拟机。和kvm不同的是，这种方式创建的虚拟机不能用VNC登录，但是可以用zlogin来登录：\n# vmadm create -f smartos.json \nSuccessfully created VM 0b3c7b3b-9f19-4d26-ab22-a8b10a9add25\n# zlogin 0b3c7b3b-9f19-4d26-ab22-a8b10a9add25 \n[Connected to zone '0b3c7b3b-9f19-4d26-ab22-a8b10a9add25' pts/2]\n   __        .                   .\n _|  |_      | .-. .  . .-. :--. |-\n|_    _|     ;|   ||  |(.-' |  | |\n  |__|   `--'  `-' `;-| `-' '  ' `-'\n                   /  ; Instance (base64 14.3.0)\n                   `-'  http://wiki.joyent.com/jpc2/Base+Instance\nZone不只是支持SmartOS，它还支持LX Branded Zones，允许你在zone里面直接运行linux。imgadm avail中列出的镜像中以lx-开头的支持LX Branded Zones。此外，使用这种方法创建虚拟机时，不必用NFS来共享数据，可以直接通过filesystems字段来指定目录映射。下面是一个lx-ubuntu-14.04的例子：\n{\n  \"brand\": \"lx\",\n  \"alias\": \"ubuntu1404\",\n  \"kernel_version\": \"3.13.0\",\n  \"max_physical_memory\": 2048,\n  \"image_uuid\": \"a21a64a0-0809-11e5-a64f-ff80e8e8086f\",\n  \"resolvers\": [\"192.168.1.1\",\"114.114.114.114\",\"8.8.8.8\",\"8.8.4.4\"],\n  \"nics\": [\n    {\n      \"nic_tag\": \"admin\",\n      \"ip\": \"192.168.1.103\",\n      \"netmask\": \"255.255.255.0\",\n      \"gateway\": \"192.168.1.1\",\n      \"primary\": true\n    }\n  ],\n  \"filesystems\": [\n    {\n      \"type\": \"lofs\",\n      \"source\": \"zones/datastore\",\n      \"target\": \"/mnt/datastore\"\n    }\n  ]\n}\n可以看到我们直接将Global Zone的zones/datastore映射到虚拟机的/mnt/datastore。然后就可以通过zlogin进行登录，设置好ssh后也可以通过ssh远程登录。\nSmartOS确实是一个很适合NAS的系统，还有更多的特性有待发掘。"
  },
  {
    "objectID": "posts/2014/07/15/1-click-building-your-mac-environment/index.html",
    "href": "posts/2014/07/15/1-click-building-your-mac-environment/index.html",
    "title": "快速构建Mac环境",
    "section": "",
    "text": "最近硬盘不幸挂掉，换了新硬盘后重装系统、搭建环境真是一个痛苦的过程。尤其是后者，各种软件的配置、开发环境的设定，非常繁琐。这里索性总结一下，怎么能够将开发、应用的环境配置系统化，使得更换系统时能够迅速重建原来的环境。这里虽然是针对Mac来说的，对于Linux应该也类似。\n作为一个开发者用户，我关心的数据主要有以下几类：\n\n代码\n各种资料、数据（照片、视频、文档、程序数据等）\n应用程序及其配置信息\n系统配置信息\n\n对于代码而言，如果是开源的，放在GitHub是最好的方案；如果是内部代码，可以考虑用GitLab搭建一个私有服务器来存放代码，当然也可以放在Dropbox之类的网盘上。对于资料文档以及比较大的数据，可以放在网盘上。无论是代码还是文档，除了网上存储之外，最好能定期备份到移动硬盘上，一来是防止网盘出问题，二来是大数据从网盘下载较慢，如果急用就比较痛苦了。所以这里我们主要侧重于后面两点：应用程序的安装配置及系统的配置。\n\n使用Homebrew管理程序\nMac中的App主要有两类：一类是从App Store中安装的；另一类是下载安装的。对于前者，没有什么太好的办法，到Purchased里面一个个重新装过就好了；对于后者，用Homebrew来管理更加方便，相比直接的下载安装而言，它是更容易自动化、更易重现的方式。\n对于dmg和pkg程序，可以用Homebrew Cask来安装。\n如果要装的程序没有在Homebrew或者Cask里面，可以在你的GitHub中建立一个Repo来存放相关的Formula/Cask，然后用brew tap将其加到Homebrew中。\nHomebrew的好处是，你很容易将当前安装的程序列表备份起来以备下次安装。另外一种备份方法是采用Brewfile，不过Homebrew已经后悔把这东西加进去了，以后也许会有更好的方案出现吧。\n\n\n管理配置文件\n安装程序其实只是最简单的一步，更麻烦的是如何对这些程序进行配置。当前一个很流行的方式是把你的配置文件放在一个Dotfiles的Repo里，然后将其符号链接到相应的位置。然后你就可以用Git轻松管理你的配置文件了。对于包含敏感信息无法放在GitHub中的信息，也可以放在Dropbox中。\n把所有程序的配置文件都搜集起来当然是一件非常繁琐的事情，而Mackup可以把你从这件事情里面解放出来，它记录了很多程序的配置文件，从而能够自动在系统中搜索这些配置文件，备份到你的目录中，然后再符号链接到相应的位置。结合GitHub或者Dropbox来进行备份，真是太方便了！\nDotfiles中还可以保存一些常用的脚本，比如mathiasbynens的dotfiles中就包含了很多OSX的设置脚本，一键运行完成你大部分的系统设置。\n然而，单靠配置文件有时候也不能完全解决问题，比如安装vim的时候，希望不但能保留.vimrc之类的配置文件，还希望能把所有的插件装上去。这时候就需要介绍下面一个系统了：Boxen。\n\n\n用Boxen自动化环境设置\nBoxen是GitHub的自动化部署工具，它能够快速为新员工构建一个开发环境。Boxen基于Puppet，它针对Mac系统做了一系列的设置，使得环境配置更加方便快捷。关于Boxen的介绍可以看看Gary Larizza的这篇博客.\nGitHub提供了一个Boxen工程的模板，叫做our-boxen，只要将其fork并安装说明文档安装即可。安装完的our-boxen包含了一个基本的开发环境（Ruby、node等），你可以在此基础上加入你自己的东西。一般来说，你可以在modules目录里面添加相关的内容：people添加和用户相关的内容，projects中添加工程相关的内容。我的个人设置在这里。\n对系统默认参数的一些配置（比如全局的Ruby版本）可以通过Hiera实现，具体参考相关说明。你可以针对用户进行一些设置，这里是我的个人设置。\n你甚至可以把代码的Repo和系统相关的配置写在文件里，下次部署时直接搞定。\nBoxen支持Homebrew/Cask，所以我们上面安装的App可以直接写文件中，下次部署时只要一个boxen命令即可。Boxen自身也只是App的安装，其GitHub帐户中包含了很多可用的App，和Homebrew/Cask相比，这些App的更新可能相对较慢，但一般会提供更多的配置选项。对于简单的的应用，我一般使用Homebrew/Cask来管理，对于配置比较复杂的（如Ruby）我会采用Boxen提供的版本。\n此外，我写了一个puppet的模块puppet-dotfiles，可以使用Mackup兼容的配置文件，直接在Boxen工程中进行配置，使得程序的配置更加自动化。该模块除了用Mackup的配置文件，还会进行了一些其它的设置，比如安装vim的时候会安装上Vundle及其它插件、自动安装prezto及其模块等。\nBoxen的另外一个好处是删除简单，只要把/opt/boxen删除即可（当然可能你还要删除/opt下的homebrew-cask之类的）。\n\n\n缓存安装文件\n虽然上述过程能够大大减轻你的负担，但是在恶劣的网络环境中，下载安装文件就会成为一个瓶颈。我的解决方案是：缓存安装文件。\nHomebrew/Cask安装程序时会把安装文件缓存下来，下次重装的时候就不会再次下载了。我的Mac是11年的型号，光驱位换了SSD，所以就把这些缓存文件备份到原来的硬盘：\n$ mv `brew --cache` \"/Volumes/Macintosh HD/\"\n$ ln -s \"/Volumes/Macintosh HD/cache\" `brew --cache`\n这样万一SSD坏掉，重装起来也会比较快一点。\n当然，编译也是一项非常耗时的任务，这个问题主要存在Homebrew中（因为Cask只是些dmg、pkg）。不过Homebrew非常佛心地提供了编译好的二进制版本（叫做Bottle），只要你用默认选项安装，就会使用二进制版本，免去你的编译之苦。然而，不幸的是，某些程序的编译过程需要具体的路径信息（比如Qt），Homebrew默认是安装在/usr/local的，而Boxen把Homebrew安装在了/opt/boxen/homebrew中，所以就不能享受到这项好处了，希望将来能够有所改进吧！\n\n\n其它方案\n对于这样一个常见问题，肯定是有很多方案的，这里有一些供参考的其它方案：\n\nosxc: 基于Ansible的一套方案。\nbattleschool: 也是基于Ansible的方案。\nkitchenplan: 基于Chef的方案。\nthoughtbot/laptop: 用于Mac和Linux安装配置的一套脚本。\n\n其实还有很多……说说你的方案吧。"
  },
  {
    "objectID": "posts/2014/07/14/master-of-puppets/index.html",
    "href": "posts/2014/07/14/master-of-puppets/index.html",
    "title": "走马观花看Puppet",
    "section": "",
    "text": "Puppet是目前最流行的一套配置管理(Configuration Management，简称CM)系统。它提供了一套简洁、强大的框架，使系统管理的重用、分享更加简单，让系统配置更加自动化。在云计算时代，动辄需要配置大量主机，它的作用更加明显。\nPuppet使用一种声明式的语言，和传统的脚本相比，你只需指定目标，而不必关注具体的执行细节。举个例子，比如我们要建立一个文件/tmp/foobar.txt，其内容为Hello World!，在Puppet中这么写就行了：\nfile { '/tmp/foobar.txt':\n  ensure  =&gt; present,\n  content =&gt; 'Hello World!',\n}\n将上述内容保存为test.pp（称为manifest），然后执行puppet apply test.pp，就会确保存在一个文件/tmp/foobar.txt，其中的内容为「Hello World!」。在这个过程中，Puppet会检查我们声明的条件是否满足，如果满足就什么也不做；如果不满足就执行相应的操作以满足我们的要求，而这个过程对用户来说是完全透明的，你不用写各种脚本去执行各种检测和修改。\n在Puppet中，file是一种资源(resource)。资源是一个相当广的概念，用户、软件包、文件、服务甚至Git的库都是资源，用puppet describe -l可以查看系统中所有的资源类型。每种资源都有一个类型（如file），一个名字（如/tmp/foobar.txt）以及一系列的属性（如ensure、content等），可以通过puppet describe &lt;resource_type&gt;得到资源的具体描述。\n通过资源声明就可以完成一些基本的任务，比如要配置一个ssh服务：\n# /root/examples/break_ssh.pp\nfile { '/etc/ssh/sshd_config':\n  ensure =&gt; file,\n  mode   =&gt; 600,\n  source =&gt; '/root/examples/sshd_config',\n}\n\nservice { 'sshd':\n  ensure     =&gt; running,\n  enable     =&gt; true,\n  subscribe  =&gt; File['/etc/ssh/sshd_config'],\n}\n其中声明了两个资源：一个配置文件，权限为600，内容从/root/examples/sshd_config复制；一个服务sshd，确保其处于运行状态。值得注意的是，上述sshd资源的最后一项是subscribe，这是什么东西呢？原来在Puppet中，执行顺序并不是按照资源的声明顺序来的，在上述例子中，就有可能sshd服务先启动起来，然后配置文件才生成，这种情况配置文件就不起作用了。\nPuppet提供了一系列方法来确保资源的执行顺序，上述的subscribe属于metaparameter，它表示当配置文件/etc/ssh/sshd_config修改后，自动重启sshd。其中File['/etc/ssh/sshd_config']是对资源的引用。除了metaparameter之外，还可以用箭头来表示顺序，上述例子也可以这么写：\n# /root/examples/break_ssh.pp\nfile { '/etc/ssh/sshd_config':\n  ensure =&gt; file,\n  mode   =&gt; 600,\n  source =&gt; '/root/examples/sshd_config',\n}\n~&gt;\nservice { 'sshd':\n  ensure     =&gt; running,\n  enable     =&gt; true,\n}\n当资源不多时，把所有东西都写到一个巨大的manifest里面还可以接受；随着你维护的东西越来越多，这种方法会让你的代码越来越难维护。Puppet提供了class和module使得我们能够更加模块化地管理代码。\n如果你像我一样从其它编程语言过来，那么很可能会被class这个关键字所迷惑：Puppet中的class不像C++或Java之类语言中的class，它只是一段有名字的代码。你可以用class把相关的代码包装起来，使其重用起来更加方便。比如上述代码可以修改为：\nclass ssh {\n  file { '/etc/ssh/sshd_config':\n    ensure =&gt; file,\n    mode   =&gt; 600,\n    source =&gt; '/root/examples/sshd_config',\n  }\n  service { 'sshd':\n    ensure     =&gt; running,\n    enable     =&gt; true,\n    subscribe  =&gt; File['/etc/ssh/sshd_config'],\n  }\n}\n\ninclude ssh\n需要注意的是，class只是定义了一段代码，只有include之后才会声明其中的资源。同一个class可以include多次，效果和include一次一样。然而，即使有了class，我们的代码仍然在一个巨大的manifest里面啊！这里就要提到module了。\nModule其实就是目录，它根据特定的结构来组织目录，并且其中的manifest符合一定的命名规则。Puppet在modulepath中搜索module，如果一个类在module中出现了，那么你可以在任何其它的manifest中声明它。比如要配置一个Apache服务器，可以把apache作为一个模块，而mod、proxy、vhost的设置都可以作为其中的manifest。\nPuppet中可以使用变量，变量以$开头。变量是有作用域的，子作用域可以访问父作用域的变量，但访问其它作用域的变量就要加上module和class前缀（如$apache::params::confdir）。此外，变量支持双引号字符串插值：\"The value is ${variable}\"。\n上述例子中，ssh配置文件的模板位置是固定的。但是，实际应用中往往根据不同的情况做修改，我们不可能针对每种情况写一个class。为此，可以使用带参数的class，上述例子可以修改为：\nclass ssh ($config_path = '/root/examples/ssd_config') {\n  file { '/etc/ssh/sshd_config':\n    ensure =&gt; file,\n    mode   =&gt; 600,\n    source =&gt; \"${config_path}\",\n  }\n  service { 'sshd':\n    ensure     =&gt; running,\n    enable     =&gt; true,\n    subscribe  =&gt; File['/etc/ssh/sshd_config'],\n  }\n}\n\nclass { 'ssh':\n  config_path =&gt; '/home/jack/ssd_config',\n}\n注意要使用带参数的class，就不能直接用include ssh（否则会使用默认参数），而是要用资源式的class声明方式，将参数作为属性传递进去，在这种情况下应该仔细组织manifest文件，不要将一个class声明两次。参数类的另外一种使用方法是通过Hiera来设置参数，这种方式能够尽量把代码和数据分开，是一种推荐的使用方式。\n即使class可以设置参数，但是我们也只能设置一组参数，如果我们需要同时设置多组参数呢？比如Apache的vhost，我们希望能够设置多个vhost，比如：\napache::vhost {'users.example.com':\n  port    =&gt; 80,\n  docroot =&gt; '/var/www/personal',\n  options =&gt; 'Indexes MultiViews',\n}\napache::vhost {'projects.example.com':\n  port    =&gt; 80,\n  docroot =&gt; '/var/www/project',\n  options =&gt; 'Indexes MultiViews',\n}\n这时候我们就需要define类型了，它所定义的类型和系统提供的资源类似，可以同时声明多个不同参数的资源。举个例子：\ndefine planfile ($user = $title, $content) {\n  file {\"/home/${user}/.plan\":\n    ensure  =&gt; file,\n    content =&gt; $content,\n    mode    =&gt; 0644,\n    owner   =&gt; $user,\n    require =&gt; User[$user],\n  }\n}\nplanfile {'nick':\n  content =&gt; \"working on foobar\"\n}\nplanfile {'katie':\n  content =&gt; \"working on cookies\"\n}\n要发挥Puppet最大的优势，必须了解Agent/Master Puppet（为什么现在都不用Master/Slave了？看这里）。不过我暂时都是单机用用，就先不去了解了。\n当然了，题目就叫走马观花，看这篇Blog你是不可能完全掌握Puppet的啦，感兴趣就去看看tutorial和reference吧！"
  },
  {
    "objectID": "posts/2014/09/10/webpack-package-manager-for-web/index.html",
    "href": "posts/2014/09/10/webpack-package-manager-for-web/index.html",
    "title": "Webpack: 为Web开发而生的模块管理器",
    "section": "",
    "text": "对于开发人员而言，好的包管理器可以让工作事半功倍。现在流行的编程语言大多有自己的包管理系统。近年来，Web开发越来越火，其开发工具也随之越来越好用了，而Webpack就是一款专为Web开发设计的包管理器。它能够很好地管理、打包Web开发中所用到的HTML、Javascript、CSS以及各种静态文件（图片、字体等），让开发过程更加高效。\n\n模块化编程\n长久以来，Web开发者都是把所需Javascript、CSS文件一股脑放进HTML里面，对于庞大的项目来说管理起来非常麻烦。Node.js的出现改变了这种状态，虽然Javascript的模块并非Node.js发明，但确实是它把这个概念发扬光大了。\n但Node.js毕竟是用于服务端的，为了将模块化技术用于浏览器，人们又造出了一大堆工具：RequireJS、Browserify、LABjs、Sea.js、Duo等。同时，由于Javascript的标准没有对模块的规范进行定义，人们又定义了一系列不同的模块定义：CommonJS、AMD、CMD、UMD等。这真是一件令人悲伤的事情，希望ES6 Module的出现能中止这种分裂的状态。\nWebpack同时支持CommonJS和AMD形式的模块，对于不支持的模块格式，还支持对模块进行shimming。举个简单的例子：\n// content.js\nmodule.exports = \"It works from content.js.\";\n// entry.js\ndocument.write(require(\"./content.js\"));\n&lt;!-- index.html --&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;meta charset=\"utf-8\"&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;script type=\"text/javascript\" src=\"bundle.js\" charset=\"utf-8\"&gt;&lt;/script&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n这里entry.js是入口文件，它加载了content.js。通过命令行对entry.js进行编译：\n$ webpack ./entry.js bundle.js\n打开index.html就会看到content.js中的内容已经被加载进来了。\nWeb开发中用到的不但有Javascript，还有CSS以及各种静态文件。Webpack定义了一种叫加载器loader的东西，它能够把各种资源文件进行转换，用正确的格式加载到浏览器中。比如对于上述程序，如果我们有一个对应的CSS文件：\n/* style.css */\nbody {\n  background: yellow;\n}\n我们修改一下entry.js来加载该CSS：\nrequire(\"!style!css!./style.css\");\ndocument.write(require(\"./content.js\"));\n然后再重新编译、打开index.html就可以看到CSS加载进来了。执行上述程序前我们必须安装所需的loader：\nnpm install --save-dev style-loader css-loader\n在编译时，css-loader会读取CSS文件，并处理其中的import，返回CSS代码；而style-loader会将返回的CSS代码作为DOM的style。如果你用的是SASS，只要把require语句改成require(\"!style!css!sass!./style.scss\")就可以了。\nWebpack提供了很多常见的loader，开发的时候可以把用到的文件都require进来，生成一个单一的Javascript，便于发布。\n上述require CSS的代码虽然功能强大，但写起来比较繁琐，Webpack支持在配置文件中进行配置，把符合条件的文件用同一组loader来进行处理。下面是我用的一组loader：\n{\n  module: {\n    loaders: [\n      {test: /\\.coffee$/, loader: 'coffee'},\n      {test: /\\.html$/,   loader: 'html'},\n      {test: /\\.json$/,   loader: 'json'},\n      {test: /\\.css$/,    loader: 'style!css!autoprefixer'},\n      {test: /\\.scss$/,   loader: 'style!css!autoprefixer!sass'},\n      {test: /\\.woff$/,   loader: \"url?limit=10000&minetype=application/font-woff\"},\n      {test: /\\.ttf$/,    loader: \"file\"},\n      {test: /\\.eot$/,    loader: \"file\"},\n      {test: /\\.svg$/,    loader: \"file\"}\n    ]\n  }\n}\n有了上述配置，直接require('./style.css')就可以了，系统会自动先执行autoprefixer，然后加载CSS，然后再加载为DOM的style。\n此外，Webpack还支持插件，实现对Javascript的压缩、替换等各种操作。\n\n\n依赖模块的管理\nWebpack自己并不提供模块的下载，但它可以和已有的包管理器很好的配合。你可以用npm、Bower、component等来管理你的Web开发资源，同时在Webpack中加载它们。\nWebpack的文件加载分为三种：\n\n绝对路径，比如require('/home/me/file')。此时会首先检查目标是否为目录，如果是目录则检查package.json的main字段（你可以让Webpack同时检查Bower的字段）；如果没有package.json或者没有main字段，则会用index作为文件名。经过上述过程，我们解析到一个绝对路径的文件名，然后会尝试为其加上扩展名（扩展名可在webpack.config.js中设置），第一个存在的文件作为最终的结果。\n相对路径，比如require('./file')。使用当前路径或配置文件中的context作为相对路径的目录。加载过程和绝对路径相似。\n模块路径，如require('module/lib/file')。会在配置文件中的所有查找目录中查找。\n\n对于复杂的模块路径，还可以设置别名。一个路径解析配置的例子：\n{\n  resolve: {\n    root: [appRoot, nodeRoot, bowerRoot],\n    modulesDirectories: [appModuleRoot],\n    alias: {\n      'angular': 'angular/angular',\n      'lodash': 'lodash/dist/lodash'\n    },\n    extensions: ['', '.js', '.coffee', '.html', '.css', '.scss']\n  }\n}\n\n\n工具的集成\nWebpack能够和grunt、gulp、karma等已有工具很好地集成。\n此外，除了输出单一文件，Webpack还支持代码分割、多入口以及运行时模块替换，是非常值得Web开发者关注的一个工具。\n最后附上我的配置文件：\n// webpack.config.js\nvar path = require('path');\nvar webpack = require('webpack');\n\nvar appRoot = path.join(__dirname, 'app');\nvar appModuleRoot = path.join(__dirname, 'app/components');\nvar bowerRoot = path.join(__dirname, 'bower_components');\nvar nodeRoot = path.join(__dirname, 'node_modules');\n\nmodule.exports = {\n  entry: 'app',\n  output: {\n    path: path.resolve('./app/assets'),\n    filename: 'bundle.js',\n    publicPath: '/assets/'\n  },\n  resolve: {\n    root: [appRoot, nodeRoot, bowerRoot],\n    modulesDirectories: [appModuleRoot],\n    alias: {\n      'angular-ui-tree': 'angular-ui-tree/dist/',\n      'angular-date-range-picker': 'angular-date-range-picker/build/'\n    },\n    extensions: ['', '.js', '.coffee', '.html', '.css', '.scss']\n  },\n  resolveLoader: {\n    root: nodeRoot\n  },\n  plugins: [\n    new webpack.ProvidePlugin({\n      _: 'lodash'\n    }),\n    new webpack.ResolverPlugin([\n      new webpack.ResolverPlugin.DirectoryDescriptionFilePlugin(\"bower.json\", [\"main\"])\n    ])\n  ],\n  module: {\n    loaders: [\n      {test: /\\.coffee$/, loader: 'coffee'},\n      {test: /\\.html$/,   loader: 'html'},\n      {test: /\\.json$/,   loader: 'json'},\n      {test: /\\.css$/,    loader: 'style!css!autoprefixer'},\n      {test: /\\.scss$/,   loader: 'style!css!autoprefixer!sass'},\n      {test: /\\.woff$/,   loader: \"url?limit=10000&minetype=application/font-woff\"},\n      {test: /\\.ttf$/,    loader: \"file\"},\n      {test: /\\.eot$/,    loader: \"file\"},\n      {test: /\\.svg$/,    loader: \"file\"}\n    ]\n  }\n};"
  },
  {
    "objectID": "posts/2013/01/06/docpad-static-site-generator-using-coffeescript/index.html",
    "href": "posts/2013/01/06/docpad-static-site-generator-using-coffeescript/index.html",
    "title": "DocPad：基于 CoffeeScript 的静态网站生成器",
    "section": "",
    "text": "DocPad 是一个静态网站生成器，同 Jekyll、Octopress 相比，它的可定制性更强； 由于是用 CoffeeScript 写的，速度也比以上两个快很多。最近两天玩了一下，感觉很不错：功能很强大，虽然有些插件不太稳定，但基本功能已经比较完备了。\n几个有意思的插件：\n\nmarked 和 highlight.js：Markdown 支持。highlight.js 是基于 Javascript 的代码高亮工具，同 Pygments 相比，它功能相对简单，但好在能和 marked 配合的比较好。DocPad 自己也有代码高亮插件，支持 Pygments，但是问题很多。下面是 highlight.js 的配置，写到 docpad.coffee 中即可：\ndocpadConfig =\n  plugins:\n    marked:\n      markedOptions:\n        pedantic: false\n        gfm: true\n        sanitize: false\n        highlight: (code, lang) -&gt;\n          aliases =\n            html: 'xml'\n          lang = aliases[lang] if aliases[lang]\n\n          hljs = require('highlight.js')\n          hljs.highlight(lang, code).value\njade：Jade 模板支持。\npaged：分页插件，和 partials插件有冲突，用的时候要小心点。\nlivereload：更新代码后自动刷新浏览器，酷吧:)\n\nDocPad 的功能非常强大，更多的功能可以去官网看看。"
  },
  {
    "objectID": "posts/2013/07/26/punctuation/index.html",
    "href": "posts/2013/07/26/punctuation/index.html",
    "title": "混乱的标点符号",
    "section": "",
    "text": "打开你经常上的几个网站，翻开你正在看的书，拿起你身边商品的包装，仔细观察一下其中的标点，有没有被用法各异的标点所困扰？中、英文之间的差异，输入法之间的差异，排版软件处理细节的不同，让标点符号变得异常混乱。"
  },
  {
    "objectID": "posts/2013/07/26/punctuation/index.html#引号撇号上标符",
    "href": "posts/2013/07/26/punctuation/index.html#引号撇号上标符",
    "title": "混乱的标点符号",
    "section": "引号、撇号、上标符",
    "text": "引号、撇号、上标符\n首先是「引号」及其面目相似的兄弟们：\n\n\n\n符号\nUnicode\n名称\nHTML\n\n\n\n\n’\nU+0027\n单直引号\n&apos;\n\n\n”\nU+0022\n双直引号\n&quot;\n\n\n‘\nU+2018\n单开弯引号\n&lsquo;\n\n\n’\nU+2019\n单闭弯引号\n&rsquo;\n\n\n“\nU+201C\n双开弯引号\n&ldquo;\n\n\n”\nU+201D\n双闭弯引号\n&rdquo;\n\n\n′\nU+2032\n上标符\n&prime;\n\n\n″\nU+2033\n双上标符\n&Prime;\n\n\n\n计算机键盘沿用了打字机的做法，将上述符号浓缩为两个：单直引号（’）和双直引号（“）。ASCII 码中也只收录了这两个字符，所以在早期的电子文档中大多是这两者身兼多职。这种引号通常叫做「Typewriter (“programmer’s”) straight quotes」——「打字机（程序员）直引号」：\n\n“Good morning, Frank,” said Hal.\ndon’t\n’06\nthe cat’s whiskers.\n6’ 2” tall.\n\n为了更好的阅读体验，也有用重音符（反引号）（`）来作为左引号的（如TeX）：\n\n``Good morning, Frank,” said Hal.\n\n随着 Unicode 的普及，计算机显示各种字符已经不成问题，让各个标点各司其职才能取得更好的阅读体验。上述标点符号应按照如下规则使用：\n\n用弯引号「’’」、「“”」作为单、双引号。\n\n\n“Good morning, Frank,” said Hal.\n‘Good morning, Frank,’ said Hal.\n\n\n撇号「’」用于缩写词、复数、所有格以及拼音分隔等。\n\n\ndon’t\n’06\nthe cat’s whiskers.\nXi’an\n\n\n上标符「′」、「″」用于表示单位、数学公式等。\n\n\n6′ 2″ tall.\nTx = x′\n\n\n直引号「’」，「“」只用于编程。\n\n\nchar *s = “Hello world”;\nchar c = ‘A’;"
  },
  {
    "objectID": "posts/2013/07/26/punctuation/index.html#连字号连接号",
    "href": "posts/2013/07/26/punctuation/index.html#连字号连接号",
    "title": "混乱的标点符号",
    "section": "连字号、连接号",
    "text": "连字号、连接号\n另几个长得比较像的是连字号和连接号：\n\n\n\n符号\nUnicode\n名称\nHTML\n\n\n\n\n-\nU+002D\n连字暨减号\n\n\n\n‐\nU+2010\n连字号\n\n\n\n−\nU+2212\n减号\n&minus;\n\n\n‒\nU+2012\n数字线\n\n\n\n–\nU+2013\nEn dash\n&ndash;\n\n\n—\nU+2014\nEm dash\n&mdash;\n\n\n\n在 ASCII 中，「-」既当减号又当连字号，有时候几个组合起来作为连接号。在 UNICODE 中这几种符号都有了单独的字符。\n\n连字号用于标志合成词或用于断字。\n\n\nice‐cream‐flavored candy.\nWe, therefore, the represen‐\ntatives of the United States\nof America…\n\n\n数字线用于连接数字（如电话号码中间的短线）。\n\n\n0571‒87932195\n\n\nEn dash 通常是 Em dash 的一半，它们的大小分别是大写字母 N 和 M 的宽度。En dash主要用于表示数值范围、对比的数值、相关的两件事或者合成词的属性部分。\n\n\nJune–July 1967\nAustralia beat American Samoa 31–0.\nPre–Civil War era\n\n\nEm dash 表示语气转折，类似于中文的破折号。\n\nDash 的用法比较复杂，各种类似的符号及其用法可以参见 Wikipedia。"
  },
  {
    "objectID": "posts/2013/07/26/punctuation/index.html#中文引号",
    "href": "posts/2013/07/26/punctuation/index.html#中文引号",
    "title": "混乱的标点符号",
    "section": "中文引号",
    "text": "中文引号\n中文的引号和英文的引号一样，都是用的弯引号，它们的 UNICODE 值也是一样的。这样导致一个问题：在文中出现引号时，是当成中文的全角呢还是英文的半角呢？因此使用直角引号「『』」的逐渐多了起来。\n\n\n\n符号\nUnicode\n名称\nHTML\n\n\n\n\n「\nU+300C\n中式单开引号\n\n\n\n」\nU+300D\n中式单闭引号\n\n\n\n『\nU+300E\n中式双开引号\n\n\n\n』\nU+300F\n中式双闭引号"
  },
  {
    "objectID": "posts/2013/07/26/punctuation/index.html#中英文混排",
    "href": "posts/2013/07/26/punctuation/index.html#中英文混排",
    "title": "混乱的标点符号",
    "section": "中英文混排",
    "text": "中英文混排\n有一种观点是混排时在中英文之间加上空格，在这方面还没有明确的规范。Adobe InDesign、Microsoft Word等软件在进行中英文混排时都会增大汉字与英文的间距，在这种情况下添加空格就没有必要；然而，大多数情况下我们没有这样的专业排版软件支持，这种情况下要想达到较好的排版效果就需要在汉字和西文之间加上半角的空格。刘昕@知乎认为：\n\n中文正文及标题中出现的英文及数字应该使用半角方式输入，并且在左右各留一个半角空格。如果这些这些半角英文及数字的左边或者右边紧接着任何的中文全角括号或者其他标点符号的话，则不需要加入半角空格。\n\n而梁海@知乎认为中英文混排中使用什么样的标点符号取决于「环境」：\n\n事实上我自己考虑排版的时候从来不从“什么夹杂什么”的角度来看问题，我的思路永远是“环境”。就是说，在我写一段文字的时候，我会有自己的意识，意识到这段文字本质上是什么语言环境，然后以此为基础。而且基本环境中也会有子环境，比如一本中文译文的全部脚注或者某一条脚注或者正文中的一大段引文完全可以是一个英文环境（但我在做这样排版的时候会尽量不让它成为一个英文子环境），然后在中文正文中的一大段英文引文中如果再出现括号内的中文解释，我会酌情使用英文括号。你那最后一句话在我看来仍旧是中文环境，中文的逗号和问号都暗示/表明了这一点，这句话还不够独立。\n\n具体采用什么样的方案要看使用场景，如果能从技术上做到中英文的隔离那是最好的了。"
  },
  {
    "objectID": "posts/2013/07/26/punctuation/index.html#输入",
    "href": "posts/2013/07/26/punctuation/index.html#输入",
    "title": "混乱的标点符号",
    "section": "输入",
    "text": "输入\n规范使用标点符号最大的障碍在于输入。大部分标点符号都是 UNICODE 的，键盘很难直接输入。根据应用场景的不同大致有以下一些方法：\n\nMicrosoft Word、Open Office 等软件本身提供了一些自动输入的方法，可以根据语境选择正确的标点符号。\n输入法一般会为标点输入提供一些便捷。特别要推荐「中州韻」输入法，它不但跨平台，还提供了强大的配置方案。\nHTML 可以使用「字符值引用」。\nWindows 可以用下「Alt code」。\nMac 下可以在「Unicode Hex Input」键盘下用「Option + xxxx」输入，其中 xxxx 表示十六进制的 UNICODE 值。\n其它的输入方法参见 Wikipedia。"
  },
  {
    "objectID": "posts/2013/04/06/markdown-to-ansi/index.html",
    "href": "posts/2013/04/06/markdown-to-ansi/index.html",
    "title": "Markdown 的 Ansi 显示",
    "section": "",
    "text": "随着 Jekyll、Octopres、Docpad 等一批静态博客生成器的兴起，Markdown 已经成为写博客的利器。不过，有时候想把博客上的文章直接贴到 BBS 上还是需要去做一些转换，把格式转换为 ANSI 颜色控制符。\n原因主要有二：\n\n直接复制网页有些链接就只有文字没有 URL，同时代码高亮之类的就没了。\n直接粘贴 Markdown 会引入一些不必要的字符（比如代码块的标记等）。\n\n看 Redcarpet 的介绍发现它支持自定义 Render，于是就写了个 Markdown 到 Ansi 的工具。原理很简单：首先，Redcarpet 把 Markdown 解析为一系列的元素；然后，定义 Redcarpet::Render::Base 的子类对这些元素进行处理。这里用 ansi 来对文字进行着色，用 Pygments.rb 来对代码进行高亮。代码如下：\nclass Ansi &lt; Redcarpet::Render::Base\n  def normal_text(text)\n    text.strip\n  end\n\n  def block_code(code, language)\n    Pygments.highlight(code,\n                       :lexer =&gt; language,\n                       :formatter =&gt; 'terminal') + \"\\n\\n\"\n  end\n\n  def double_emphasis(text)\n    \" #{ansi(text, :yellow, :on_red)} \"\n  end\n\n  # Other elements goes here\nend\n\nmd = Redcarpet::Markdown.new(Ansi, :fenced_code_blocks =&gt; true)\nmd.render('Hello **markdown**\\n')\n写了一个简单的 Gem，安装方法如下：\n$ gem install md2ansi\n欢迎 fork。"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Byte-Sized Blog",
    "section": "",
    "text": "Welcome to my blog where I share thoughts on technology, programming, and more.\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n40%键盘YDPM40\n\n\n \n\n\nhardware\n\n\n \n\n\n\n\n\nMar 18, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n网件WNDR4300上安装配置OpenWrt\n\n\n \n\n\nnas\n\n\n \n\n\n\n\n\nDec 2, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSmartOS折腾笔记\n\n\n \n\n\nnas\n\n\n \n\n\n\n\n\nJul 8, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n备份Mac AppStore中安装的应用\n\n\n \n\n\ndevops\n\n\n \n\n\n\n\n\nFeb 16, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNix: 纯函数式包管理器\n\n\n \n\n\ndevops\n\n\n \n\n\n\n\n\nSep 21, 2014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWebpack: 为Web开发而生的模块管理器\n\n\n \n\n\nweb\n\n\n \n\n\n\n\n\nSep 10, 2014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n阿里云服务器的Docker配置\n\n\n \n\n\ndevops\n\n\n \n\n\n\n\n\nJul 30, 2014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n快速构建Mac环境\n\n\n \n\n\ndevops\n\n\n \n\n\n\n\n\nJul 15, 2014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n走马观花看Puppet\n\n\n \n\n\ndevops\n\n\n \n\n\n\n\n\nJul 14, 2014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDocker on Mac\n\n\n \n\n\ndevops\n\n\n \n\n\n\n\n\nJun 6, 2014\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n混乱的标点符号\n\n\n \n\n\nwriting\n\n\n \n\n\n\n\n\nJul 26, 2013\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPython的方法解析顺序(MRO)\n\n\n \n\n\npython\n\n\n \n\n\n\n\n\nJul 25, 2013\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMarkdown 的 Ansi 显示\n\n\n \n\n\nweb\n\n\n \n\n\n\n\n\nApr 6, 2013\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nC++11 和 C++98 的 ABI 兼容性\n\n\n \n\n\ncpp\n\n\n \n\n\n\n\n\nJan 27, 2013\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDocPad：基于 CoffeeScript 的静态网站生成器\n\n\n \n\n\nweb\n\n\n \n\n\n\n\n\nJan 6, 2013\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2013/07/25/python-mro/index.html",
    "href": "posts/2013/07/25/python-mro/index.html",
    "title": "Python的方法解析顺序(MRO)",
    "section": "",
    "text": "对于支持继承的编程语言来说，其方法（属性）可能定义在当前类，也可能来自于基类，所以在方法调用时就需要对当前类和基类进行搜索以确定方法所在的位置。而搜索的顺序就是所谓的「方法解析顺序」（Method Resolution Order，或MRO）。对于只支持单继承的语言来说，MRO 一般比较简单；而对于 Python 这种支持多继承的语言来说，MRO 就复杂很多。\n先看一个「菱形继承」的例子：\n\n\n\n\n\nclassDiagram\n    class A {\n        +show()\n    }\n    class B\n    class C {\n        +show()\n    }\n    class D\n\n\n    A &lt;|-- B\n    A &lt;|-- C\n    B &lt;|-- D\n    C &lt;|-- D\n\n\n\n\n\n\n如果 x 是 D 的一个实例，那么 x.show() 到底会调用哪个 show 方法呢？如果按照 [D, B, A, C] 的搜索顺序，那么 x.show() 会调用 A.show()；如果按照 [D, B, C, A] 的搜索顺序，那么 x.show() 会调用 C.show()。由此可见，MRO 是把类的继承关系线性化的一个过程，而线性化方式决定了程序运行过程中具体会调用哪个方法。既然如此，那什么样的 MRO 才是最合理的？Python 中又是如何实现的呢？\nPython 至少有三种不同的 MRO：\n\n经典类（classic class）的深度遍历。\nPython 2.2 的新式类（new-style class）预计算。\nPython 2.3 的新式类的C3 算法。它也是 Python 3 唯一支持的方式。\n\n\n经典类的 MRO\nPython 有两种类：经典类（classic class）和新式类（new-style class）。两者的不同之处在于新式类继承自 object。在 Python 2.1 以前，经典类是唯一可用的形式；Python 2.2 引入了新式类，使得类和内置类型更加统一；在 Python 3 中，新式类是唯一支持的类。\n经典类采用了一种很简单的 MRO 方法：从左至右的深度优先遍历。以上述「菱形继承」为例，其查找顺序为 [D, B, A, C, A]，如果只保留重复类的第一个则结果为 [D, B, A, C]。我们可以用 inspect.getmro 来获取类的 MRO：\n&gt;&gt;&gt; import inspect\n&gt;&gt;&gt; class A:\n...     def show(self):\n...         print \"A.show()\"\n...\n&gt;&gt;&gt; class B(A): pass\n&gt;&gt;&gt; class C(A):\n...     def show(self):\n...         print \"C.show()\"\n...\n&gt;&gt;&gt; class D(B, C): pass\n&gt;&gt;&gt; inspect.getmro(D)\n(&lt;class __main__.D at 0x105f0a6d0&gt;, &lt;class __main__.B at 0x105f0a600&gt;, &lt;class __main__.A at 0x105f0a668&gt;, &lt;class __main__.C at 0x105f0a738&gt;)\n&gt;&gt;&gt; x = D()\n&gt;&gt;&gt; x.show()\nA.show()\n这种深度优先遍历对于简单的情况还能处理的不错，但是对于上述「菱形继承」其结果却不尽如人意：虽然 C.show() 是 A.show() 的更具体化版本（显示了更多的信息），但我们的 x.show() 没有调用它，而是调用了 A.show()。这显然不是我们希望的结果。\n对于新式类而言，所有的类都继承自 object，所以「菱形继承」是非常普遍的现象，因此不可能采用这种 MRO 方式。\n\n\nPython 2.2 的新式类 MRO\n为解决经典类 MRO 所存在的问题，Python 2.2 针对新式类提出了一种新的 MRO 计算方式：在定义类时就计算出该类的 MRO 并将其作为类的属性。因此新式类可以直接通过 __mro__ 属性获取类的 MRO。\nPython 2.2 的新式类 MRO 计算方式和经典类 MRO 的计算方式非常相似：它仍然采用从左至右的深度优先遍历，但是如果遍历中出现重复的类，只保留最后一个。重新考虑上面「菱形继承」的例子，由于新式类继承自 object 因此类图稍有改变：\n\n\n\n\n\nclassDiagram\n    class object\n    class A {\n        +show()\n    }\n    class B\n    class C {\n        +show()\n    }\n    class D\n\n    object &lt;|-- A \n    A &lt;|-- B\n    A &lt;|-- C\n    B &lt;|-- D\n    C &lt;|-- D\n\n\n\n\n\n\n按照深度遍历，其顺序为 [D, B, A, object, C, A, object]，重复类只保留最后一个，因此变为 [D, B, C, A, object]。代码为：\n&gt;&gt;&gt; class A(object):\n...     def show(self):\n...         print \"A.show()\"\n...\n&gt;&gt;&gt; class B(A): pass\n&gt;&gt;&gt; class C(A):\n...     def show(self):\n...         print \"C.show()\"\n...\n&gt;&gt;&gt; class D(B, C): pass\n&gt;&gt;&gt; D.__mro__\n(&lt;class '__main__.D'&gt;, &lt;class '__main__.B'&gt;, &lt;class '__main__.C'&gt;, &lt;class '__main__.A'&gt;, &lt;type 'object'&gt;)\n&gt;&gt;&gt; x = D()\n&gt;&gt;&gt; x.show()\nC.show()\n这种 MRO 方式已经能够解决「菱形继承」问题，再让我们看个稍微复杂点的例子：\n\n\n\n\n\nclassDiagram\n    class object\n    class X\n    class Y\n    class A\n    class B\n    class C\n\n    object &lt;|-- X\n    object &lt;|-- Y\n    X &lt;|-- A\n    Y &lt;|-- A\n    X &lt;|-- B\n    Y &lt;|-- B\n    A &lt;|-- C\n    B &lt;|-- C\n\n\n\n\n\n\n&gt;&gt;&gt; class X(object): pass\n&gt;&gt;&gt; class Y(object): pass\n&gt;&gt;&gt; class A(X, Y): pass\n&gt;&gt;&gt; class B(Y, X): pass\n&gt;&gt;&gt; class C(A, B): pass\n首先进行深度遍历，结果为 [C, A, X, object, Y, object, B, Y, object, X, object]；然后，只保留重复元素的最后一个，结果为 [C, A, B, Y, X, object]。Python 2.2 在实现该方法的时候进行了调整，使其更尊重基类中类出现的顺序，其实际结果为 [C, A, B, X, Y, object]。\n这样的结果是否合理呢？首先我们看下各个类中的方法解析顺序：对于 A 来说，其搜索顺序为 [A, X, Y, object]；对于 B，其搜索顺序为 [B, Y, X, object]；对于 C，其搜索顺序为 [C, A, B, X, Y, object]。我们会发现，B 和 C 中 X、Y 的搜索顺序是相反的！也就是说，当 B 被继承时，它本身的行为竟然也发生了改变，这很容易导致不易察觉的错误。此外，即使把 C 搜索顺序中 X 和 Y 互换仍然不能解决问题，这时候它又会和 A 中的搜索顺序相矛盾。\n事实上，不但上述特殊情况会出现问题，在其它情况下也可能出问题。其原因在于，上述继承关系违反了线性化的「 单调性原则 」。Michele Simionato对单调性的定义为：\n\nA MRO is monotonic when the following is true: if C1 precedes C2 in the linearization of C, then C1 precedes C2 in the linearization of any subclass of C. Otherwise, the innocuous operation of deriving a new class could change the resolution order of methods, potentially introducing very subtle bugs.\n\n也就是说，子类不能改变基类的方法搜索顺序。在 Python 2.2 的 MRO 算法中并不能保证这种单调性，它不会阻止程序员写出上述具有二义性的继承关系，因此很可能成为错误的根源。\n除了单调性之外，Python 2.2 及 经典类的 MRO 也可能违反继承的「 局部优先级 」，具体例子可以参见官方文档。采用一种更好的 MRO 方式势在必行。\n\n\nC3 MRO\n为解决 Python 2.2 中 MRO 所存在的问题，Python 2.3以后采用了C3 方法来确定方法解析顺序。你如果在 Python 2.3 以后版本里输入上述代码，就会产生一个异常，禁止创建具有二义性的继承关系：\n&gt;&gt;&gt; class C(A, B): pass\nTraceback (most recent call last):\n  File \"&lt;ipython-input-8-01bae83dc806&gt;\", line 1, in &lt;module&gt;\n    class C(A, B): pass\nTypeError: Error when calling the metaclass bases\n    Cannot create a consistent method resolution\norder (MRO) for bases X, Y\n我们把类 C 的线性化（MRO）记为 L[C] = [C1, C2,…,CN]。其中 C1 称为 L[C] 的头，其余元素 [C2,…,CN] 称为尾。如果一个类 C 继承自基类 B1、B2、……、BN，那么我们可以根据以下两步计算出 L[C]：\n\nL[object] = [object]\nL[C(B1…BN)] = [C] + merge(L[B1]…L[BN], [B1]…[BN])\n\n这里的关键在于 merge，其输入是一组列表，按照如下方式输出一个列表：\n\n检查第一个列表的头元素（如 L[B1] 的头），记作 H。\n若 H 未出现在其它列表的尾部，则将其输出，并将其从所有列表中删除，然后回到步骤1；否则，取出下一个列表的头部记作 H，继续该步骤。\n重复上述步骤，直至列表为空或者不能再找出可以输出的元素。如果是前一种情况，则算法结束；如果是后一种情况，说明无法构建继承关系，Python 会抛出异常。\n\n该方法有点类似于图的拓扑排序，但它同时还考虑了基类的出现顺序。我们用 C3 分析一下刚才的例子。\nobject，X，Y 的线性化结果比较简单：\nL[object] = [object]\nL[X] = [X, object]\nL[Y] = [Y, object]\nA 的线性化计算如下：\nL[A] = [A] + merge(L[X], L[Y], [X], [Y])\n     = [A] + merge([X, object], [Y, object], [X], [Y])\n     = [A, X] + merge([object], [Y, object], [Y])\n     = [A, X, Y] + merge([object], [object])\n     = [A, X, Y, object]\n注意第3步，merge([object], [Y, object], [Y]) 中首先输出的是 Y 而不是 object。这是因为 object 虽然是第一个列表的头，但是它出现在了第二个列表的尾部。所以我们会跳过第一个列表，去检查第二个列表的头部，也就是 Y。Y 没有出现在其它列表的尾部，所以将其输出。\n同理，B 的线性化结果为：\nL[B] = [B, Y, X, object]\n最后，我们看看 C 的线性化结果：\nL[C] = [C] + merge(L[A], L[B], [A], [B])\n     = [C] + merge([A, X, Y, object], [B, Y, X, object], [A], [B])\n     = [C, A] + merge([X, Y, object], [B, Y, X, object], [B])\n     = [C, A, B] + merge([X, Y, object], [Y, X, object])\n到了最后一步我们没有办法继续计算下去 了：X 虽然是第一个列表的头，但是它出现在了第二个列表的尾部；Y 虽然是第二个列表的头，但是它出现在了第一个列表的尾部。因此，我们无法构建一个没有二义性的继承关系，只能手工去解决（比如改变 B 基类中 X、Y 的顺序）。\n我们再看一个没有冲突的例子：\n\n\n\n\n\nclassDiagram\n    class object\n    class A\n    class B\n    class C\n    class D\n    class E\n    class F\n\n    object &lt;|-- D\n    object &lt;|-- E\n    object &lt;|-- F\n    D &lt;|-- B\n    D &lt;|-- C\n    E &lt;|-- B\n    F &lt;|-- C\n    B &lt;|-- A\n    C &lt;|-- A\n\n\n\n\n\n\n计算过程如下：\nL[object] = [object]\nL[D] = [D, object]\nL[E] = [E, object]\nL[F] = [F, object]\nL[B] = [B, D, E, object]\nL[C] = [C, D, F, object]\nL[A] = [A] + merge(L[B], L[C], [B], [C])\n     = [A] + merge([B, D, E, object], [C, D, F, object], [B], [C])\n     = [A, B] + merge([D, E, object], [C, D, F, object], [C])\n     = [A, B, C] + merge([D, E, object], [D, F, object])\n     = [A, B, C, D] + merge([E, object], [F, object])\n     = [A, B, C, D, E] + merge([object], [F, object])\n     = [A, B, C, D, E, F] + merge([object], [object])\n     = [A, B, C, D, E, F, object]\n当然，可以用代码验证类的 MRO，上面的例子可以写作：\n&gt;&gt;&gt; class D(object): pass\n&gt;&gt;&gt; class E(object): pass\n&gt;&gt;&gt; class F(object): pass\n&gt;&gt;&gt; class B(D, E): pass\n&gt;&gt;&gt; class C(D, F): pass\n&gt;&gt;&gt; class A(B, C): pass\n&gt;&gt;&gt; A.__mro__\n(&lt;class '__main__.A'&gt;, &lt;class '__main__.B'&gt;, &lt;class '__main__.C'&gt;, &lt;class '__main__.D'&gt;, &lt;class '__main__.E'&gt;, &lt;class '__main__.F'&gt;, &lt;type 'object'&gt;)"
  },
  {
    "objectID": "posts/2013/01/27/abi-compatibility-between-c-plus-plus-11-and-c-plus-plus-98/index.html",
    "href": "posts/2013/01/27/abi-compatibility-between-c-plus-plus-11-and-c-plus-plus-98/index.html",
    "title": "C++11 和 C++98 的 ABI 兼容性",
    "section": "",
    "text": "C++11 出来已经好几年了，对其中有些特性还是很感兴趣的，比如 rvalue reference、lambda、alias templates、range-based for 等，正好最近在写 C++ 的代码，就准备尝试一下。\nMac OS X 下面主要的编译器是 Clang，对于 C++11 的支持还是很不错的。 不过 Clang 默认是用的还是 C++98 的标准，要支持 C++11 必须使用两个选项：\n\n-std=c++11: 使用 C++11 的标准进行编译。\n-stdlib=libc++: 使用 libc++。libc++ 是重新实现的 C++ 标准库，对 C++11 有较好的支持。 如果不加该选项，Clang 就会是用老的 libstdc++，如果你使用了 C++11 标准库中的内容就会出错。\n\n看起来修改还是挺简单的，然后就把这两项加到我的 CXXFLAGS 里面，不幸的是跳出来一大堆 link error ……\n原来我用了一些 OpenCV 之类的库，而我的库都是通过 Homebrew 安装的。Homebrew 在编译这些库的时候是用的是默认的 libstdc++，而 libc++ 和 libstdc++ 是不兼容的，所以出现了 link error。\n解决方法只能是重新编译 OpenCV 等库，使用 libc++。 但是这样同时也要保证 OpenCV 等依赖的那些库也是用 libc++，而依赖 OpenCV 等库的程序最好也是用 libc++，这工作量就有点太大了！——当然，如果只用 C++11 的语法而不使用库还是可以的，即只用 -std=c++11。\n好吧，还是暂时放弃吧，等什么时候 -std=c++11 -stdlib=libc++ 成为默认参数的时候再搞吧。 GCC似乎也有这种 C++11 和 C++98 库不兼容问题，看来也不好搞:("
  },
  {
    "objectID": "posts/2020/03/18/ydpm40-keyboard/index.html",
    "href": "posts/2020/03/18/ydpm40-keyboard/index.html",
    "title": "40%键盘YDPM40",
    "section": "",
    "text": "最近看到有人晒的Planck EZ，对40%键盘非常心动，不过Planck EZ的价格还是太高了，于是在咸鱼上入了一把YDPM40。YDPM40是YANG设计的，分为YDP40和YDM40两种布局，前者是类似于Planck的直排，而后者更接近于一般键盘的斜排。我买的这把是YDM40，共44个键，非常适合极简主义者以及囊中羞涩（毕竟需要的轴比较少）、喜欢折腾的人。\n对于40%键盘，简洁固然有了，但是也给使用者一个难题：如何保证打字体验？答案是「层」。层其实并非一个很新的概念，考虑一下我们使用的键盘，同一个字母的大小写都是由一个键来实现的，输入小写字母的时候直接按该键，输入大写字母的时候按住Shift再按对应的键。这其实相当于把键盘分为两层：大写字母和小写字母，其中小写字母是默认层，按住Shift瞬时切换到大写字母层。大部分键盘还有一个Caps Lock键，按一下就直接打开了大写字母层。\nYDMP40基于hasu写的TMK固件，该固件的初衷是给HHKB加上可编程接口（以及蓝牙支持），其中对层的支持更加强大，为客制化键盘提供了非常强大的工具。TMK层的示意图如下：\nTMK最多支持32层，YDMP40支持8层。每一层都有一个开关状态，也有对应的优先级；对于键盘上的每个键，我们可以设置它在每一层的值：一般键值、透明或者禁用。在我们按下每个键时，首先对激活的层按照优先级从高到低进行查询，如果有键值或者是禁用，则停止；如果遇到透明值，则继续到低优先级的层查询。通过这样一种简单的机制，就可以在同一个键上叠加不同的值，然后根据切换层的开关状态来实现多种输入效果，对于小键盘而言实在是非常强大的工具。YANG提供了一个网站来进行各个层的设置，设置完之后可以载固件，用提供的工具来刷固件。\n在定义布局时，我想尽量保持布局和其他键盘一致，同时使得常用的键都能够在默认层上，所以复用了很多的键（比如单按左空格就是空格，长按或与其他键组合就是开启第7层），这是我的键盘布局：\n我把次常用的数字键以及符号设置到了第7层，这是为了使用YDMP里面的一个「特殊功能」，也就是「单按↑为向上，长按为按住R Shift并瞬间开启第七层」，这样就可以按住上箭头直接输入数字键上面的符号了。\n总体来说，对这把键盘还是比较满意的，虽然键比较少，但是通过层和键的复用，可以最大程度满足日常使用。此外，由于键盘比较小，能够使大部分的键都在手的范围内，不用大范围的移动也算一种优势。如果说缺点，把常用键都塞到默认层还是有点勉强，如果能多一列可能会好很多。"
  },
  {
    "objectID": "posts/2020/03/18/ydpm40-keyboard/index.html#更新",
    "href": "posts/2020/03/18/ydpm40-keyboard/index.html#更新",
    "title": "40%键盘YDPM40",
    "section": "3.24更新",
    "text": "3.24更新\n经过几天的使用，发现:;键按起来不太方便，但是这两个符号使用的还挺多的: :在vim里面用的很多，而;在微软双拼里面代表ing。我对布局进行了一些微调: 在第7层将右空格设置为:;，同时在Karabiner Elements里面针对YDM40做了如下设定：\n\n如果是英文输入法，交换冒号:和分号;，这样我就可以同时按住两个空格键输入vim的命令了。\n如果是双拼输入法，交换回车和分号，这样就可以按回车当成ing，同时按住两个空格回车了。\n\nKarabiner里面支持针对设备和输入法设置，还是比较方便的，我的karabiner的设置如下， 点击链 接 即可添加到karabiner elements的complex modifications中：\n\n\nydmp40.json\n\n{\n  \"title\": \"YDPM40 key settings\",\n  \"rules\": [\n    {\n      \"description\": \"Exchange semicolon and colon\",\n      \"manipulators\": [\n        {\n          \"conditions\": [\n            {\n              \"input_sources\": [\n                {\n                  \"input_source_id\": \"com\\\\.apple\\\\.keylayout\\\\.ABC\"\n                }\n              ],\n              \"type\": \"input_source_if\"\n            },\n            {\n              \"type\": \"device_if\",\n              \"identifiers\": [\n                {\n                  \"vendor_id\": 65261,\n                  \"product_id\": 576,\n                  \"description\": \"YDM40\"\n                }\n              ]\n            }\n          ],\n          \"from\": {\n            \"key_code\": \"semicolon\",\n            \"modifiers\": {\n              \"optional\": [\n                \"caps_lock\"\n              ]\n            }\n          },\n          \"to\": [\n            {\n              \"key_code\": \"semicolon\",\n              \"modifiers\": [\n                \"left_shift\"\n              ]\n            }\n          ],\n          \"type\": \"basic\"\n        },\n        {\n          \"conditions\": [\n            {\n              \"input_sources\": [\n                {\n                  \"input_source_id\": \"com\\\\.apple\\\\.keylayout\\\\.ABC\"\n                }\n              ],\n              \"type\": \"input_source_if\"\n            }, \n            {\n              \"type\": \"device_if\",\n              \"identifiers\": [\n                {\n                  \"vendor_id\": 65261,\n                  \"product_id\": 576,\n                  \"description\": \"YDM40\"\n                }\n              ]\n            }\n          ],\n          \"from\": {\n            \"key_code\": \"semicolon\",\n            \"modifiers\": {\n              \"mandatory\": [\n                \"shift\"\n              ],\n              \"optional\": [\n                \"caps_lock\"\n              ]\n            }\n          },\n          \"to\": [\n            {\n              \"key_code\": \"semicolon\"\n            }\n          ],\n          \"type\": \"basic\"\n        }\n      ]\n    },\n    {\n      \"description\": \"Exchange return and semicolon\",\n      \"manipulators\": [\n        {\n          \"conditions\": [\n            {\n              \"input_sources\": [\n                {\n                  \"input_source_id\": \"com\\\\.apple\\\\.inputmethod\\\\.SCIM\\\\.Shuangpin\"\n                }\n              ],\n              \"type\": \"input_source_if\"\n            }, \n            {\n              \"type\": \"device_if\",\n              \"identifiers\": [\n                {\n                  \"vendor_id\": 65261,\n                  \"product_id\": 576,\n                  \"description\": \"YDM40\"\n                }\n              ]\n            }\n          ],\n          \"from\": {\n            \"key_code\": \"semicolon\",\n            \"modifiers\": {\n              \"optional\": [\n                \"caps_lock\"\n              ]\n            }\n          },\n          \"to\": [\n            {\n              \"key_code\": \"return_or_enter\"\n            }\n          ],\n          \"type\": \"basic\"\n        },\n        {\n          \"conditions\": [\n            {\n              \"input_sources\": [\n                {\n                  \"input_source_id\": \"com\\\\.apple\\\\.inputmethod\\\\.SCIM\\\\.Shuangpin\"\n                }\n              ],\n              \"type\": \"input_source_if\"\n            },\n            {\n              \"type\": \"device_if\",\n              \"identifiers\": [\n                {\n                  \"vendor_id\": 65261,\n                  \"product_id\": 576,\n                  \"description\": \"YDM40\"\n                }\n              ]\n            }\n          ],\n          \"from\": {\n            \"key_code\": \"return_or_enter\",\n            \"modifiers\": {\n              \"optional\": [\n                \"caps_lock\"\n              ]\n            }\n          },\n          \"to\": [\n            {\n              \"key_code\": \"semicolon\"\n            }\n          ],\n          \"type\": \"basic\"\n        }\n      ]\n    }\n  ]\n}"
  },
  {
    "objectID": "posts/2014/09/21/nix-the-purely-functional-package-manager/index.html",
    "href": "posts/2014/09/21/nix-the-purely-functional-package-manager/index.html",
    "title": "Nix: 纯函数式包管理器",
    "section": "",
    "text": "Nix是一个Linux/Unix下的包管理器，它支持原子升级和回滚、能够同时安装同一个包的多个版本、支持多用户，能够更加简单地搭建开发、构建环境。它最大的卖点在于 函数式 的管理方式：把软件包作为函数式语言的值，这些值由没有副作用的函数构建，一旦构建完就不再改变，这意味着你的软件运行环境一旦构建就不会改变——这对于可重现的开发而言非常重要。\n\n安装\n如果你想充分体验Nix的强大功能，可以安装NixOS，它是一个构建于Nix之上的Linux发型版。\n如果你不想装一个新的系统，或者像我一样主要用Mac OSX工作，也可以只安装Nix。最简单的方式就是在Terminal里面执行如下命令：\n$ bash &lt;(curl https://nixos.org/nix/install)\n然后把下面这段脚本加入到你的shell启动文件中(~/.zshrc、~/.bashrc等)：\nif [ -e $HOME/.nix-profile/etc/profile.d/nix.sh ]; then\n  source $HOME/.nix-profile/etc/profile.d/nix.sh;\nfi\n然后就可以查看有什么可用的包：\n\n$ nix-env -qa\n安装一个包：\n$ nix-env -i hello\n卸载一个包：\n$ nix-env -e hello\n升级所有的包：\n$ nix-channel --update nixpkgs\n$ nix-env -u '*'\n回滚上一步操作：\n$ nix-env --rollback\n垃圾回收不用的包：\n$ nix-collect-garbage -d\n\n\n包管理\n安装Nix时主要创建了两个目录：/nix和$HOME/.nix-profile。我们来看看安装的包到底是如何组织的，比如当前有一个包hello：\n$ which hello\n/Users/hjw/.nix-profile/bin/hello\n可以看到，hello来自于$HOME/.nix-profile，而后者是一个符号链接，其指向如下：\n\n\n\n\n\n\n\n\nG\n\n\n\na\n\n~/.nix-profile\n\n\n\nb\n\n/nix/var/nix/profiles/default\n\n\n\na-&gt;b\n\n\n\n\n\nc\n\n/nix/var/nix/profiles/default-6-link\n\n\n\nb-&gt;c\n\n\n\n\n\nd\n\n/nix/store/hsw97dr9h9z3wmlwhx2lib8r3k2f9wv3-user-environment\n\n\n\nc-&gt;d\n\n\n\n\n\n\n\n\nFigure 1: Nix profile.\n\n\n\n\n\n进一步查看最后一个目录（省略部分输出）：\n$ ls -l /nix/store/hsw97dr9h9z3wmlwhx2lib8r3k2f9wv3-user-environment\nbin\netc -&gt; /nix/store/2vk1g8qkly4aqwx6ks49mzkd5kxhrd5f-nix-1.8pre3766_809ca33/etc\ninclude -&gt; /nix/store/2vk1g8qkly4aqwx6ks49mzkd5kxhrd5f-nix-1.8pre3766_809ca33/include\n……\n\n$ ls -l /nix/store/hsw97dr9h9z3wmlwhx2lib8r3k2f9wv3-user-environment/bin\nccmake -&gt; /nix/store/r5rr3h6fg9sb0vararwh3plm2v9p8hcm-cmake-2.8.12.2/bin/ccmake\ncmake -&gt; /nix/store/r5rr3h6fg9sb0vararwh3plm2v9p8hcm-cmake-2.8.12.2/bin/cmake\n……\n可以发现，实际的文件都是存在/nix/store中的。这也是Nix管理包的方式：所有的包都存放在/nix/store中，而用户访问的都是指向/nix/store中文件的符号链接。\nProfile是Nix管理包的方式，在/nix/var/nix/profiles中保存了当前的profile：\n$ ls -l /nix/var/nix/profiles\ndefault -&gt; default-6-link\ndefault-5-link -&gt; /nix/store/g7l19z0c0ka41irwkn4mz67a0z85xydg-user-environment\ndefault-6-link -&gt; /nix/store/hsw97dr9h9z3wmlwhx2lib8r3k2f9wv3-user-environment\nper-user\n其中default就是当前的profile。如果我们删除一个包呢？\n$ nix-env -e hello\nuninstalling ‘hello-2.9’\nbuilding path(s) ‘/nix/store/816saagv6v8s19b2sksbgzjj0ljf5qfk-user-environment’\ncreated 62 symlinks in user environment\n\n$ ls -l /nix/var/nix/profiles\ndefault -&gt; default-7-link\ndefault-5-link -&gt; /nix/store/g7l19z0c0ka41irwkn4mz67a0z85xydg-user-environment\ndefault-6-link -&gt; /nix/store/hsw97dr9h9z3wmlwhx2lib8r3k2f9wv3-user-environment\ndefault-7-link -&gt; /nix/store/816saagv6v8s19b2sksbgzjj0ljf5qfk-user-environment\nper-user\n注意到删除一个包会生成一个新的profile —— default-7-link，而default也会指向新生成的profile。这也是Nix的工作方式，你删除包的时候，包其实并没有被删除，而是生成了一个不包含原来包的新profile！而你随时可以回到原来的状态。如果我们后悔删除hello了，那么可以回滚上述操作：\n$ which hello\nhello not found\n$ nix-env --rollback\nswitching from generation 7 to 6\n$ which hello\n/Users/hjw/.nix-profile/bin/hello\n$ ls -l /nix/var/nix/profiles\ndefault -&gt; default-6-link\ndefault-5-link -&gt; /nix/store/g7l19z0c0ka41irwkn4mz67a0z85xydg-user-environment\ndefault-6-link -&gt; /nix/store/hsw97dr9h9z3wmlwhx2lib8r3k2f9wv3-user-environment\ndefault-7-link -&gt; /nix/store/816saagv6v8s19b2sksbgzjj0ljf5qfk-user-environment\nper-user\n可以看到，回滚之后default又指向了default-6-link，hello又可以用了。Profile使用起来非常灵活，我们可以很方便地在各个profile之间切换：\n$ nix-env --list-generations\n   5   2014-09-13 20:58:33\n   6   2014-09-19 10:00:58   (current)\n   7   2014-09-21 21:16:57\n$ nix-env --switch-generation 7\nswitching from generation 6 to 7\n$ nix-env --switch-profile /nix/var/nix/profiles/my-profile\n$ ls -l ~/.nix-profile\n/Users/hjw/.nix-profile -&gt; /nix/var/nix/profiles/my-profile\n如果我们从来不真正删除包，毫无疑问硬盘慢慢就会被占满，Nix支持垃圾回收。我们需要首先删除不用的profile：\n$ nix-env --delete-generations 5\nremoving generation 5\n$ nix-env --delete-generations old\nremoving generation 6\n$ nix-env --list-generations\n   7   2014-09-21 21:16:57   (current)\n然后，可以运行垃圾回收的命令。这里的垃圾回收跟编程语言的垃圾回收机制很像，一个包如果没有profile用到它就会被删除：\n$ nix-store --gc\n如果你不确定哪些东西会被删除，可以先把要删除的东西打印一下看看：\n$ nix-store --gc --print-dead\n还有另外一个命令，它会删除/nix/var/nix/profiles下所有profile的老版本，可以用来清理你的系统：\n$ nix-collect-garbage -d\nNix的profile其实是可以放在任意位置的，但是垃圾回收的时候之后回收/nix/var/nix/gcroots下所指向的那些profile目录：\n$ ls -l /nix/var/nix/gcroots\nauto\nprofiles -&gt; /nix/var/nix/profiles\n\n\nChannel\nNix的Channel存储了包的集合，可以通过命令添加Channel：\n$ nix-channel --add http://nixos.org/channels/nixpkgs-unstable\n更新Channel:\n$ nix-channel --update\n升级已有的包：\n$ nix-env -u '*'\n此外，Nix还提供了很方便的工具让你把包及其依赖导出、导入以及通过SSH拷贝到另一台机器上：\n$ nix-store --export $(nix-store -qR $(type -p firefox)) &gt; firefox.closure\n$ nix-store --import &lt; firefox.closure\n$ nix-copy-closure --to alice@itchy.example.org $(type -p firefox)\n\n\nNix表达式\nNix的包是由Nix表达式描述的，它所使用的Nix expression language是一种支持惰性求值的纯函数式语言。下面是一个简单的hello包的描述：\n{ stdenv, fetchurl, perl }:\n\nstdenv.mkDerivation {\n  name = \"hello-2.1.v1\";\n  builder = ./builder.sh;\n  src = fetchurl {\n    url = ftp://ftp.nluug.nl/pub/gnu/hello/hello-2.1.1.tar.gz;\n    md5 = \"70c9ccvf9fac07f762c24f2df2290784d\";\n  };\n  inherit perl;\n}\n这个描述其实就是一个函数，{stdenv, fetchurl, perl}是函数的参数，表示构建这个包需要什么东西，stdenv提供了一个标准的构建环境，fetchurl通过url抓取一个文件，而perl是Perl的解释器。mkDerivation是stdenv提供的一个函数，它通过一个属性集合来构建一个包。mkDerivation的参数也就是后面花括弧括起来的那部分是一个集合，描述了这个包的属性，如名字、源代码、以及所需的解释器，其中的builder表示构建这个包的脚本：\nsource $stdenv/setup\n\nPATH=$perl/bin:$PATH\n\ntar xvfz $src\ncd hello-*\n./configure --prefix=$out\nmake 5\nmake install\n更具体的Nix expression这里就不赘述，有兴趣的可以查看相关文档。\n\n\n总结\nNix是一个非常强大的包管理工具，它可以非常方便地解决包的依赖以及多版本共存的问题，对于那些没有包管理系统的语言（如C/C++）是一个比较好的选择；对于包管理很弱的语言（如Python）也能够提供一个更好的解决方法；对于涉及到多中语言的项目，能够以一种统一的方式来管理各种包，对开发者而言是一个非常好的工具。\n此外，Nix所提供的包管理机制应该可以和Docker结合起来。比如本地开发的时候使用Nix，发布时将相关的包打包形成一个Docker镜像，实现可重现的构建。\n如果说Nix的缺点，那就是相比apt、yum、pacman、homebrew之类比较成熟的包管理器，它包的数量还比较少，特别是在Mac上，有很多包还是处于broken的状态。不过Nix的开发比较活跃，即使你现在还没有用它，也值得去关注一下。\n最后说一句，Nix其实也不是真的纯函数式 :-)"
  },
  {
    "objectID": "posts/2014/07/30/docker-on-aliyun/index.html",
    "href": "posts/2014/07/30/docker-on-aliyun/index.html",
    "title": "阿里云服务器的Docker配置",
    "section": "",
    "text": "最近把程序放到阿里云服务器上，并尝试用Docker来部署。阿里云的镜像列表里面已经有了Ubuntu 14.04 64位，可以直接安装Docker。然而，由于阿里云服务器的特殊情况，需要进行配置才能用。\n安装完Docker之后，发现Docker服务并没有起来，检查日志发现有这么一段：\n[/var/lib/docker|3c476c9d] -job init_networkdriver() = ERR (1)\nCould not find a free IP address range for interface 'docker0'. Please configure its address manually and run 'docker -b docker0'\n搜了下Docker的issues，发现这个问题挺多人遇到过。究其原因，要从Docker的启动过程说起，在Docker的文档中有这么一段话：\n\nWhen Docker starts, it creates a virtual interface named docker0 on the host machine. It randomly chooses an address and subnet from the private range defined by RFC 1918 that are not in use on the host machine, and assigns it to docker0.\n\n也就是说，Docker在启动时，会创建一个虚拟接口docker0，并为其选择一个没有在宿主机器上使用的地址和子网。这个docker0其实并非一般的网络接口，而是一个虚拟的网桥（Ethernet Bridge），其作用是为了容器（Container）和宿主（Host）机器之间的通信。每当Docker启动一个容器时，它都会创建一对对等接口（“peer” interface）。这对接口有点类似于管道，向其中的一个接口发送数据包，另外一个接口就会接收到。Docker把其中的一个接口分配给容器，作为它的eth0接口；然后，为另外一个接口分配一个唯一的名字比如vethAQI2QT，将其分配给宿主机器，并将其绑定到docker0这个网桥上。这样每个容器都可以和宿主机器进行通信了。\n那么，在阿里云中为什么会启动失败呢？在Docker的源代码搜索上述错误信息，可以看出问题出在createBridge这个函数中。该函数会检查下列IP段:\nvar addrs = []string{\n    \"172.17.42.1/16\",\n    \"10.0.42.1/16\",\n    \"10.1.42.1/16\",\n    \"10.42.42.1/16\",\n    \"172.16.42.1/24\",\n    \"172.16.43.1/24\",\n    \"172.16.44.1/24\",\n    \"10.0.42.1/24\",\n    \"10.0.43.1/24\",\n    \"192.168.42.1/24\",\n    \"192.168.43.1/24\",\n    \"192.168.44.1/24\",\n}\n对于每个IP段，Docker会检查它是否和当前机器的域名服务器或路由表有重叠，如果有的话，就放弃该IP段。让我们看看阿里云服务器的路由表：\n$ route -n\nDestination     Gateway         Genmask         Flags Metric Ref    Use Iface\n0.0.0.0         121.40.83.247   0.0.0.0         UG    0      0        0 eth1\n10.0.0.0        10.171.223.247  255.0.0.0       UG    0      0        0 eth0\n10.171.216.0    0.0.0.0         255.255.248.0   U     0      0        0 eth0\n121.40.80.0     0.0.0.0         255.255.252.0   U     0      0        0 eth1\n172.16.0.0      10.171.223.247  255.240.0.0     UG    0      0        0 eth0\n192.168.0.0     10.171.223.247  255.255.0.0     UG    0      0        0 eth0\n检查一下路由表会发现，Docker所检查的IP段在路由表中都有了，所以不能找到一个有效的IP段。\n解决方法其实也很简单，简单粗暴的方法就是把内网的网卡信息直接删掉，它在路由表中所对应的信息也没有了:\n$ sudo ifconfig eth0 down\n这种方法的缺点也很明显：你就无法访问内网了，而阿里云的内部流量是不收费的（用mirrors.aliyuncs.com来升级不占用公网流量），这点还是比较可惜的。\n另一种方法是把路由表中不用的项删除，这样Docker就能找到能用的IP段了：\n$ sudo route del -net 172.16.0.0/12\n$ sudo service docker start\n$ ifconfig docker0\ndocker0   Link encap:Ethernet  HWaddr 56:84:7a:fe:97:99\n          inet addr:172.17.42.1  Bcast:0.0.0.0  Mask:255.255.0.0\n重新启动服务，可以看到docker0已经建立成功，所用的IP地址就是我们删除路由表项之后腾出来的IP地址。采用这种方法，我们仍然可以使用内网的服务。如果要每次启动的时候设置，编辑/etc/network/interfaces，将up route add -net 172.16.0.0 ....那一行删掉即可。"
  },
  {
    "objectID": "posts/2014/06/06/docker-on-mac/index.html",
    "href": "posts/2014/06/06/docker-on-mac/index.html",
    "title": "Docker on Mac",
    "section": "",
    "text": "在虚拟化领域，Docker是一颗冉冉升起的新星。它构建于LXC之上，比传统的虚拟机技术相比，它没有操作系统层，因此更加轻量化，灵活性和可移植性也更好。\nDocker有两个主要的部件：daemon和作为客户端的二进制程序「docker」。docker作为客户端，把相应指令发送给daemon来执行。因为Docker使用了Linux内核的一些特性，因此只能运行在具体比较新内核的64位Linux上，其它平台上必须借助虚拟机才能运行。\n在Mac上，主要有两种基于VirtualBox的运行方式：第一种是借助boot2docker；第二种是使用Vagrant来管理虚拟机。\nboot2docker使用了一个非常轻量的Linux发行版CoreOS来作为Docker的运行环境，启动很快、占用空间很少。通过Homebrew来安装非常方便：\n$ brew install boot2docker docker\nboot2docker的一个问题是和Mac之间共享文件非常不方便，官方给出的方案是用Samba来共享文件。\n我更喜欢的一种方式是用Vagrant来管理Docker。Vagrant是一个管理虚拟机的软件，1.6版本加入了对Docker的支持，可以在Vagrant中对Docker进行管理。Vagrant可以把Docker作为Provider，在Vagrantfile配置Docker相关的操作。一个简单的Vagrantfile的例子：\nVagrant.configure(\"2\") do |config|\n  config.vm.provider \"docker\" do |d|\n    d.image = \"ubuntu:14.04\"\n  end\nend\n这个配置文件表示，启动Docker的时候使用ubuntu:14.04这个image。然后，执行操作：\n$ vagrant up --provider=docker\n在非Linux系统上，Docker是需要运行在虚拟机中的。如果没有配置虚拟机（比如上述例子），Vagrant会自动使用boot2docker作为虚拟机。当然，你可以指定一个已有的Vagrantfile作为Docker的运行主机：\nVagrant.configure(\"2\") do |config|\n  config.vm.provider \"docker\" do |d|\n    d.vagrant_vagrantfile = \"../path/to/Vagrantfile\"\n  end\nend\n同直接使用boot2docker相比，Vagrant提供了非常便捷的手段处理Mac和虚拟机之间的交互，如文件夹同步、端口映射等。在进行文件夹同步时，Vagrant会尝试使用最佳方式进行同步，比如对boot2docker会使用rsync进行同步。\nboot2docker虽然比较精简，但是功能毕竟有限，我使用了一个Ubuntu 14.04来作为Docker的运行主机，相应的Vagrantfile如下：\nVAGRANTFILE_API_VERSION = \"2\"\n\nVagrant.configure(VAGRANTFILE_API_VERSION) do |config|\n  # Box\n  config.vm.box = \"phusion/ubuntu-14.04-amd64\"\n  config.vm.box_check_update = false\n\n  # Provisioners\n  config.vm.provision \"shell\", path: \"apt.sh\"\n  config.vm.provision \"docker\"\n  config.vm.provision \"shell\", path: \"docker.sh\"\n\n  config.vm.network \"forwarded_port\", guest: 4243, host: 4243\nend\n注意中间的Provisioner部分，Vagrant的Provisioner的主要作用是自动安装一些软件、执行一些任务。上面的apt.sh是一个脚本，用来修改Ubuntu的apt源；docker.sh用来修改Docker的配置参数。值得注意的是，Vagrant还提供了Docker的Provisoner，用来安装、配置Docker。当你运行的虚拟机中没有安装Docker时，它会自动帮你安装最新的Docker。\n在最后一行，我设置了一个端口映射，将虚拟机的Docker daemon的端口4243映射到本地，这样就可以使用Mac中Homebrew所带的docker客户端来执行相应的操作了（要注意Mac客户端的版本需和虚拟机中Docker daemon的版本一致）。\n我们只要运行vagrant up，Docker的运行环境就搭建好了。Vagrant中有很多对Docker的支持，使得我们能够更方便地自动化搭建开发、部署环境，具体可以参考Vagrant和Docker的文档。"
  },
  {
    "objectID": "posts/2015/12/02/openwrt-setup/index.html",
    "href": "posts/2015/12/02/openwrt-setup/index.html",
    "title": "网件WNDR4300上安装配置OpenWrt",
    "section": "",
    "text": "WNDR4300是对OpenWrt支持比较好的一款路由器：其内存和闪存都是128M，有比较好的ROM支持，是一个比较适合折腾的路由器。"
  },
  {
    "objectID": "posts/2015/12/02/openwrt-setup/index.html#shadowsocks",
    "href": "posts/2015/12/02/openwrt-setup/index.html#shadowsocks",
    "title": "网件WNDR4300上安装配置OpenWrt",
    "section": "Shadowsocks",
    "text": "Shadowsocks\n首先，在路由器上安装shadowsocks的客户端：\n$ opkg install http://openwrt-dist.sourceforge.net/releases/ar71xx/packages/shadowsocks-libev_2.4.1-1_ar71xx.ipk\n安装时到shadowsock的下载页面确定软件的具体版本。如果你空间有限，也可以装polarssl版本。\n编辑/etc/shadowsock.json，填上你shadowsock服务器的信息。\n然后设置shadowsock自动启动：\n$ /etc/init.d/shadowsocks enable\n$ /etc/init.d/shadowsocks start\n你可以将自己系统的SOCKS Proxy设置为192.168.1.1:1080，测试下shadowsocks是否工作正常。如果工作正常，将/etc/init.d/shadowsocks文件中的ss-local换成ss-redir并重启shadowsocks，表示我们要用shadowsocks进行转发。\n\nDSN服务器设置\n为了防止DNS污染，利用dnsmasq将gfwlist中的域名用OpenDNS解析。OpenWrt自带的dnsmasq功能是有限制的，首先安装上完全版的dnsmasq，并安装ipset包:\n$ opkg remove dnsmasq && opkg install dnsmasq-full\n$ opkg install ipset\n我们创建一个名为gfw的ipset，并设置所有ipset中的IP都通过shadowsocks转发。\n$ ipset create gfw hash:ip\n$ iptables -t nat -A PREROUTING -p tcp -m set --match-set gfw dst -j REDIRECT --to-port 1079\n为了防止路由器重启时规则丢失，可以将上述规则写到/etc/firewall.user文件中。\n然后利用gfwlist2dnsmasq生成dnsmasq_list.conf文件，记得运行命令之前将gfwlist2dnsmasq.py中的mydnsip改成208.67.220.220，mydnsport改成443，ipsetname改成gfw。\n$ python gfwlist2dnsmasq.py\n修改dnsmasq的配置文件/etc/dnsmasq.conf，在最后加上一句：\nconf-dir=/etc/dnsmasq.d\n最后将生成的dnsmasq_list.conf拷贝到/etc/dnsmasq.d中，重启dnsmasq：\n$ /etc/init.d/dnsmasq restart\n搞定！"
  }
]